{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35249f28-a9de-4d08-8daf-3eb302860157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb39a75a-5969-4d55-b925-2a3a8f2f2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StructField,IntegerType, StringType, TimestampType\n",
    "from pyspark.sql.functions import from_unixtime, col, to_date, date_format, unix_timestamp, lit,regexp_replace,split, udf, spark_partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92e73ca-bbd0-4aea-8199-bb0a8fc6cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/21 11:35:26 WARN Utils: Your hostname, hari-HP-Laptop-15s-du2xxx resolves to a loopback address: 127.0.1.1; using 172.17.0.1 instead (on interface docker0)\n",
      "25/06/21 11:35:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/06/21 11:35:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c671a2-df0b-4220-8056-a3a344dc4d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ea7b972dc30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8700a2ac-f46c-4b4c-af27-4328d2cae8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+\n",
      "|emp_id|emp_name|dept_id|\n",
      "+------+--------+-------+\n",
      "|     1|    John|      1|\n",
      "|     2|    Emma|      2|\n",
      "|     3|     Raj|   null|\n",
      "|     4|    Nina|      4|\n",
      "+------+--------+-------+\n",
      "\n",
      "+-------+---------+\n",
      "|dept_id|dept_name|\n",
      "+-------+---------+\n",
      "|      1|       HR|\n",
      "|      2|     Tech|\n",
      "|      3|Marketing|\n",
      "|   null|     Temp|\n",
      "|      1|       HR|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames for Employees and Departments\n",
    "data_employees = [(1, \"John\", 1), (2, \"Emma\", 2), (3, \"Raj\", None), (4, \"Nina\", 4)]\n",
    "data_departments = [(1, \"HR\"), (2, \"Tech\"), (3, \"Marketing\"), (None, \"Temp\"),(1, \"HR\")]\n",
    "\n",
    "columns_employees = [\"emp_id\", \"emp_name\", \"dept_id\"]\n",
    "columns_departments = [\"dept_id\", \"dept_name\"]\n",
    "\n",
    "df_employees = spark.createDataFrame(data_employees, columns_employees)\n",
    "df_departments = spark.createDataFrame(data_departments, columns_departments)\n",
    "\n",
    "# Perform INNER JOIN\n",
    "# since `inner` is the default join type, we can omit it\n",
    "#df_joined = df_employees.join(df_departments, df_employees.dept_id == df_departments.dept_id)\n",
    "\n",
    "# Show the result\n",
    "#df_joined.show()\n",
    "\n",
    "df_employees.show()\n",
    "df_departments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705e9042-5c5e-48d1-865b-87eff473b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repart = df_employees.coalesce(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b7f2b3-8ad3-49c6-af6c-ddb52c15260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/21 11:51:23 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "df_repart_cached = df_repart.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f601c74-f295-4988-9824-6d9eb628ffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees.rdd.getNumPartitions()\n",
    "df_repart.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "164177dd-686a-482a-9167-bfb8562906a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|dept_id|count|\n",
      "+-------+-----+\n",
      "|   null|    1|\n",
      "|      1|    1|\n",
      "|      2|    1|\n",
      "|      4|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_employees.groupBy(col('dept_id')).count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "720eefc9-e054-4db6-9f9a-7fea6e01c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|dept_id|count|\n",
      "+-------+-----+\n",
      "|      1|    1|\n",
      "|      2|    1|\n",
      "|      4|    1|\n",
      "|   null|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "(df_repart.groupBy(col('dept_id')).count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe23eb41-b92b-46fc-8598-7d962cac8848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+-------+\n",
      "|emp_id|emp_name|dept_id|part_id|\n",
      "+------+--------+-------+-------+\n",
      "|     1|    John|      1|      0|\n",
      "|     2|    Emma|      2|      0|\n",
      "|     3|     Raj|   null|      0|\n",
      "|     4|    Nina|      4|      0|\n",
      "+------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_repart_cached.withColumn('part_id',spark_partition_id())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f8f9a6-8215-4f95-823a-34a813a8989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+-------+\n",
      "|emp_id|emp_name|dept_id|part_id|\n",
      "+------+--------+-------+-------+\n",
      "|     1|    John|      1|      1|\n",
      "|     2|    Emma|      2|      3|\n",
      "|     3|     Raj|   null|      5|\n",
      "|     4|    Nina|      4|      7|\n",
      "+------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_employees.withColumn('part_id',spark_partition_id())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669a129-6028-4232-b58e-b94cd74f3078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de0f2e-cb66-4e3c-a6b8-29c84bfd1b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddfd23-1d7e-49e5-9abf-a155f858199c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228ffb7-b8ed-44b5-a35d-042a7e5bb4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb12ee-8cb9-4678-976a-2ce1cab995aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fbcd0-5056-422a-b7f3-5b5bf9ca30a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84aae6c1-086d-40a9-8595-e4c5059df1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join FullOuter, (dept_id#336L = dept_id#340L)\n",
      ":- LogicalRDD [emp_id#334L, emp_name#335, dept_id#336L], false\n",
      "+- LogicalRDD [dept_id#340L, dept_name#341], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "emp_id: bigint, emp_name: string, dept_id: bigint, dept_id: bigint, dept_name: string\n",
      "Join FullOuter, (dept_id#336L = dept_id#340L)\n",
      ":- LogicalRDD [emp_id#334L, emp_name#335, dept_id#336L], false\n",
      "+- LogicalRDD [dept_id#340L, dept_name#341], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join FullOuter, (dept_id#336L = dept_id#340L)\n",
      ":- LogicalRDD [emp_id#334L, emp_name#335, dept_id#336L], false\n",
      "+- LogicalRDD [dept_id#340L, dept_name#341], false\n",
      "\n",
      "== Physical Plan ==\n",
      "SortMergeJoin [dept_id#336L], [dept_id#340L], FullOuter\n",
      ":- *(2) Sort [dept_id#336L ASC NULLS FIRST], false, 0\n",
      ":  +- Exchange hashpartitioning(dept_id#336L, 200), true, [id=#1775]\n",
      ":     +- *(1) Scan ExistingRDD[emp_id#334L,emp_name#335,dept_id#336L]\n",
      "+- *(4) Sort [dept_id#340L ASC NULLS FIRST], false, 0\n",
      "   +- Exchange hashpartitioning(dept_id#340L, 200), true, [id=#1780]\n",
      "      +- *(3) Scan ExistingRDD[dept_id#340L,dept_name#341]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df_employees.join(df_departments, on= df_employees['dept_id'] == df_departments['dept_id'], how=\"outer\")\n",
    "#df = df_employees.crossJoin(df_departments)\n",
    "df.explain(True)\n",
    "\n",
    "df.rdd.getNumPartitions()\n",
    "\n",
    "df_part = df.coalesce(10)\n",
    "df_part.count()\n",
    "\n",
    "df_part.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5846d94-91a7-4a10-85a7-494468f2a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de21c34a-5a8d-4feb-ba60-b2f0f56eb150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+-------+---------+-------+\n",
      "|emp_id|emp_name|dept_id|dept_id|dept_name|part_id|\n",
      "+------+--------+-------+-------+---------+-------+\n",
      "|     3|     Raj|   null|   null|     null|      2|\n",
      "|  null|    null|   null|   null|     Temp|      2|\n",
      "|     1|    John|      1|      1|       HR|      3|\n",
      "|     1|    John|      1|      1|       HR|      3|\n",
      "|  null|    null|   null|      3|Marketing|      5|\n",
      "|     2|    Emma|      2|      2|     Tech|      6|\n",
      "|     4|    Nina|      4|   null|     null|      7|\n",
      "+------+--------+-------+-------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast,spark_partition_id\n",
    "\n",
    "df = df_employees.join(broadcast(df_departments), on= df_employees['dept_id'] == df_departments['dept_id'], how=\"left\")\n",
    "#df = df_employees.crossJoin(df_departments)\n",
    "df_part.withColumn('part_id',spark_partition_id()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf635e-2757-457a-996f-a20f7a7e4ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bf77abe-060c-49cf-8a26-707df9d19f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"hari prasath\", \"hari prasath weds ellakiya\", \"hari prasath works in infosys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89cfeff0-4a7d-4e54-91ec-411960a89e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b3a8f8b-cfea-4534-b3d4-eb470f59d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_1 = (\n",
    "        rdd.flatMap(lambda x:x.split())\n",
    "        .map(lambda x:(x,1))\n",
    "        .reduceByKey(lambda x,y : x + y)\n",
    ")\n",
    "\n",
    "\n",
    "# Whow this works \n",
    "'''\n",
    "Rdd reads line by line\n",
    "1) flatMap() -> we use flatMap to flatten the string ==> hari prasth => [hari,prasath]\n",
    "2) map() -> maps every list with a value ==> [hari, prasath] => [(hari,1),(prasath,1]\n",
    "3) reduceByKey() -> use to group the results and add the keys ==> [\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba6f088c-61c6-4fa2-b3d8-045e3fec35b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('infosys', 1),\n",
       " ('hari', 3),\n",
       " ('in', 1),\n",
       " ('ellakiya', 1),\n",
       " ('works', 1),\n",
       " ('prasath', 3),\n",
       " ('weds', 1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7e11dad-8cef-4ceb-9659-50543280747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_2 = (\n",
    "        rdd.flatMap(lambda x:x.split())\n",
    "        .map(lambda x:(x,1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63e0f727-f994-4fd1-aa1f-07af5fe22289",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute '_get_object_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrdd_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/rdd.py:2034\u001b[0m, in \u001b[0;36mRDD.groupByKey\u001b[0;34m(self, numPartitions, partitionFunc)\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merger\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   2033\u001b[0m locally_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(combine, preservesPartitioning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2034\u001b[0m shuffled \u001b[38;5;241m=\u001b[39m \u001b[43mlocally_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitionBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumPartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitionFunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroupByKey\u001b[39m(it):\n\u001b[1;32m   2037\u001b[0m     merger \u001b[38;5;241m=\u001b[39m ExternalGroupBy(agg, memory, serializer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/rdd.py:1888\u001b[0m, in \u001b[0;36mRDD.partitionBy\u001b[0;34m(self, numPartitions, partitionFunc)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext) \u001b[38;5;28;01mas\u001b[39;00m css:\n\u001b[1;32m   1886\u001b[0m     pairRDD \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPairwiseRDD(\n\u001b[1;32m   1887\u001b[0m         keyed\u001b[38;5;241m.\u001b[39m_jrdd\u001b[38;5;241m.\u001b[39mrdd())\u001b[38;5;241m.\u001b[39masJavaPairRDD()\n\u001b[0;32m-> 1888\u001b[0m     jpartitioner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonPartitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumPartitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartitionFunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mvalueOfPair(pairRDD\u001b[38;5;241m.\u001b[39mpartitionBy(jpartitioner))\n\u001b[1;32m   1891\u001b[0m rdd \u001b[38;5;241m=\u001b[39m RDD(jrdd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx, BatchedSerializer(outputSerializer))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1560\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1556\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m   1557\u001b[0m     temp_args \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1559\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m-> 1560\u001b[0m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[1;32m   1562\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1564\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1565\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1567\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1560\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1556\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m   1557\u001b[0m     temp_args \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1559\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m-> 1560\u001b[0m     [\u001b[43mget_command_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[1;32m   1562\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1564\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1565\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1567\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:298\u001b[0m, in \u001b[0;36mget_command_part\u001b[0;34m(parameter, python_proxy_pool)\u001b[0m\n\u001b[1;32m    296\u001b[0m         command_part \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m interface\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     command_part \u001b[38;5;241m=\u001b[39m REFERENCE_TYPE \u001b[38;5;241m+\u001b[39m \u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_id\u001b[49m()\n\u001b[1;32m    300\u001b[0m command_part \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m command_part\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute '_get_object_id'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e2a2d-3bad-40cd-be23-902fa4662100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c718df3-90c7-4b5f-9fd8-a1201a2e60dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddfdc3-f7f6-4cd9-9ffd-d20cc63a049c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b32851-a9fd-4056-bd2a-0ed3fc000b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d43508-6342-4cbb-b13a-402265dc21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('userId',IntegerType(), False),\n",
    "        StructField('movieId',IntegerType(), False),\n",
    "        StructField('tag',StringType(),False),\n",
    "        StructField('timestamp',IntegerType(),False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8220208b-c904-4cf0-9abe-c93b3b9e54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.schema(schema).option(\"header\",True).format(\"csv\").load(\"data/tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810726f2-b53e-4e0a-b3fc-824e4d4bbf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaaf8168-cd06-4d94-be07-b549a028e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_timecnv = (\n",
    "        data.withColumn('timestamp',from_unixtime(col('timestamp'),'yyyy-MM-dd HH:MM:SS.SS' ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d497375-f6de-4e07-a032-bc5bff0e97a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+----------------------+\n",
      "|userId|movieId|tag              |timestamp             |\n",
      "+------+-------+-----------------+----------------------+\n",
      "|18    |4141   |Mark Waters      |2009-04-24 23:04:00.00|\n",
      "|65    |208    |dark hero        |2013-05-10 07:05:00.00|\n",
      "|65    |353    |dark hero        |2013-05-10 07:05:00.00|\n",
      "|65    |521    |noir thriller    |2013-05-10 07:05:00.00|\n",
      "|65    |592    |dark hero        |2013-05-10 07:05:00.00|\n",
      "|65    |668    |bollywood        |2013-05-10 07:05:00.00|\n",
      "|65    |898    |screwball comedy |2013-05-10 07:05:00.00|\n",
      "|65    |1248   |noir thriller    |2013-05-10 07:05:00.00|\n",
      "|65    |1391   |mars             |2013-05-10 07:05:00.00|\n",
      "|65    |1617   |neo-noir         |2013-05-10 07:05:00.00|\n",
      "|65    |1694   |jesus            |2013-05-10 07:05:00.00|\n",
      "|65    |1783   |noir thriller    |2013-05-10 07:05:00.00|\n",
      "|65    |2022   |jesus            |2013-05-10 07:05:00.00|\n",
      "|65    |2193   |dragon           |2013-05-10 07:05:00.00|\n",
      "|65    |2353   |conspiracy theory|2013-05-10 07:05:00.00|\n",
      "|65    |2662   |mars             |2013-05-10 07:05:00.00|\n",
      "|65    |2726   |noir thriller    |2013-05-10 07:05:00.00|\n",
      "|65    |2840   |jesus            |2013-05-10 07:05:00.00|\n",
      "|65    |3052   |jesus            |2013-05-10 07:05:00.00|\n",
      "|65    |5135   |bollywood        |2013-05-10 07:05:00.00|\n",
      "+------+-------+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_timecnv.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5fb4a1-42c8-4b62-8c70-077ef0115911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_tags(column):\n",
    "    return column.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7418c80a-ee42-4cac-869c-6a44c67b9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.udf.register('udf_name', function, return type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49389446-7b1f-44cd-9868-6aa6d3d0d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_lower = udf(lower_tags,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ce0996-09bd-4f01-ae9d-6bcffc048402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_udf = data_timecnv.withColumn('lower_tags', udf_lower(col('tag')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a78a52-85f5-46f3-8464-7fd285a9354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+--------------------+-----------------+\n",
      "|userId|movieId|              tag|           timestamp|       lower_tags|\n",
      "+------+-------+-----------------+--------------------+-----------------+\n",
      "|    18|   4141|      Mark Waters|2009-04-24 23:04:...|      mark waters|\n",
      "|    65|    208|        dark hero|2013-05-10 07:05:...|        dark hero|\n",
      "|    65|    353|        dark hero|2013-05-10 07:05:...|        dark hero|\n",
      "|    65|    521|    noir thriller|2013-05-10 07:05:...|    noir thriller|\n",
      "|    65|    592|        dark hero|2013-05-10 07:05:...|        dark hero|\n",
      "|    65|    668|        bollywood|2013-05-10 07:05:...|        bollywood|\n",
      "|    65|    898| screwball comedy|2013-05-10 07:05:...| screwball comedy|\n",
      "|    65|   1248|    noir thriller|2013-05-10 07:05:...|    noir thriller|\n",
      "|    65|   1391|             mars|2013-05-10 07:05:...|             mars|\n",
      "|    65|   1617|         neo-noir|2013-05-10 07:05:...|         neo-noir|\n",
      "|    65|   1694|            jesus|2013-05-10 07:05:...|            jesus|\n",
      "|    65|   1783|    noir thriller|2013-05-10 07:05:...|    noir thriller|\n",
      "|    65|   2022|            jesus|2013-05-10 07:05:...|            jesus|\n",
      "|    65|   2193|           dragon|2013-05-10 07:05:...|           dragon|\n",
      "|    65|   2353|conspiracy theory|2013-05-10 07:05:...|conspiracy theory|\n",
      "|    65|   2662|             mars|2013-05-10 07:05:...|             mars|\n",
      "|    65|   2726|    noir thriller|2013-05-10 07:05:...|    noir thriller|\n",
      "|    65|   2840|            jesus|2013-05-10 07:05:...|            jesus|\n",
      "|    65|   3052|            jesus|2013-05-10 07:05:...|            jesus|\n",
      "|    65|   5135|        bollywood|2013-05-10 07:05:...|        bollywood|\n",
      "+------+-------+-----------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):                                  (0 + 1) / 1]\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 642, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_udf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92eba46-ee8e-46ea-b1f1-833061f235ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(name='!', description=None, className='org.apache.spark.sql.catalyst.expressions.Not', isTemporary=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6777800c-3b4c-4356-9959-85ba2a74adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for udf in udfs:\n",
    "    print(udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc41444-c516-4a10-a012-2e887d1201c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdc07c-af71-4a70-a2b8-47a10164b55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1db057bc-4638-4e41-8243-209a50c7b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"extra_spaces\",lit(\"this      is    a  column\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa8c6b27-3a39-4e94-8a9f-a48a2d95378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data.withColumn(\"replaced_extra_spaces\",regexp_replace(col('extra_spaces'),r\"\\s+\",\" \")).withColumn('convt_str',split(col('replaced_extra_spaces'),' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2ddfdd9d-05d6-44b8-ab35-3d6dd2623964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465564"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4aac25e9-a237-4816-bda2-abb9b1f16e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2bed265d-bde1-49a4-94ec-357cf3e03014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862256"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.withColumn('ex_arr',explode(col('convt_str'))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c55e5c1-e2b0-4f6b-9241-bc5c2b1f4bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/14 10:55:57 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 4, schema size: 3\n",
      "CSV file: file:///home/hari/python-notebooks/data/tags.csv\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "(\n",
    "    data.write.mode('overwrite')\n",
    "        .parquet(f'output_data/tags_{datetime.date.today()}')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5992daae-8077-41a0-86d6-a690ba2b9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b91e5871-2abf-4384-b3a8-899f346dcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.option(\"header\",True).csv(\"data/upi_transactions_2024.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e961efb1-920e-4a1f-bc42-0727e22df64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- transaction type: string (nullable = true)\n",
      " |-- merchant_category: string (nullable = true)\n",
      " |-- amount (INR): string (nullable = true)\n",
      " |-- transaction_status: string (nullable = true)\n",
      " |-- sender_age_group: string (nullable = true)\n",
      " |-- receiver_age_group: string (nullable = true)\n",
      " |-- sender_state: string (nullable = true)\n",
      " |-- sender_bank: string (nullable = true)\n",
      " |-- receiver_bank: string (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- network_type: string (nullable = true)\n",
      " |-- fraud_flag: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- is_weekend: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd19d6f5-f8ce-4cd3-8272-1b18b1c3112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cd14949-5a1e-4dc4-b790-09450b518ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanatize_column_name(column : str, replace_str : str) -> DataFrame:\n",
    "\n",
    "    def sanitize(column):\n",
    "        sanitize_df = re.sub(r'\\W+',replace_str,column)\n",
    "        sanitize_df = sanitize_df.strip(replace_str)\n",
    "        return sanitize_df\n",
    "\n",
    "    return sanitize(column).lower()    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f8f7f4d-4601-429e-b5a5-905103922fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction_id', 'timestamp', 'transaction_type', 'merchant_category', 'amount_inr', 'transaction_status', 'sender_age_group', 'receiver_age_group', 'sender_state', 'sender_bank', 'receiver_bank', 'device_type', 'network_type', 'fraud_flag', 'hour_of_day', 'day_of_week', 'is_weekend']\n"
     ]
    }
   ],
   "source": [
    "# Column Renaming \n",
    "import re\n",
    "columns = [sanatize_column_name(column,'_') for column in df.columns]\n",
    "\n",
    "print(columns)\n",
    "df_renamed = df.toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a7f20a5-6f39-418e-858c-a85a01509962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- merchant_category: string (nullable = true)\n",
      " |-- amount_inr: string (nullable = true)\n",
      " |-- transaction_status: string (nullable = true)\n",
      " |-- sender_age_group: string (nullable = true)\n",
      " |-- receiver_age_group: string (nullable = true)\n",
      " |-- sender_state: string (nullable = true)\n",
      " |-- sender_bank: string (nullable = true)\n",
      " |-- receiver_bank: string (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- network_type: string (nullable = true)\n",
      " |-- fraud_flag: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- is_weekend: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f1c96027-3fbd-412f-b981-24b6811dfc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:==============>                                           (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------------------+-----------------------+----------------+------------------------+----------------------+------------------------+------------------+-----------------+-------------------+-----------------+------------------+----------------+-----------------+-----------------+----------------+\n",
      "|transaction_id_nulls|timestamp_nulls|transaction_type_nulls|merchant_category_nulls|amount_inr_nulls|transaction_status_nulls|sender_age_group_nulls|receiver_age_group_nulls|sender_state_nulls|sender_bank_nulls|receiver_bank_nulls|device_type_nulls|network_type_nulls|fraud_flag_nulls|hour_of_day_nulls|day_of_week_nulls|is_weekend_nulls|\n",
      "+--------------------+---------------+----------------------+-----------------------+----------------+------------------------+----------------------+------------------------+------------------+-----------------+-------------------+-----------------+------------------+----------------+-----------------+-----------------+----------------+\n",
      "|                   0|              0|                     0|                      0|               0|                       0|                     0|                       0|                 0|                0|                  0|                0|                 0|               0|                0|                0|               0|\n",
      "+--------------------+---------------+----------------------+-----------------------+----------------+------------------------+----------------------+------------------------+------------------+-----------------+-------------------+-----------------+------------------+----------------+-----------------+-----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_renamed.select([\n",
    "    F.count(F.when((F.col(c).isNull()) | (F.col(c) == '' )| (F.isnan(c)),c)).alias(f'{c}_nulls')\n",
    "    for c in df_renamed.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a5a671ec-d4cc-4548-a223-22c39dc59edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|transaction_status|count(1)|\n",
      "+------------------+--------+\n",
      "|           SUCCESS|  237554|\n",
      "|            FAILED|   12446|\n",
      "+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.groupBy('transaction_status').agg(F.count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3c5fafb1-222a-4675-812c-90c35dab0a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+\n",
      "|transaction_id|          timestamp|transaction_type|merchant_category|amount_inr|transaction_status|sender_age_group|receiver_age_group|sender_state|sender_bank|receiver_bank|device_type|network_type|fraud_flag|hour_of_day|day_of_week|is_weekend|\n",
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+\n",
      "| TXN0000000024|2024-04-27 20:17:46|             P2M|          Grocery|       264|            FAILED|           18-25|             36-45|       Delhi|      Kotak|     Yes Bank|    Android|          4G|         0|         20|   Saturday|         1|\n",
      "| TXN0000000025|2024-01-04 17:25:02|    Bill Payment|          Grocery|       814|            FAILED|           26-35|             18-25|   Karnataka|        SBI|        Kotak|    Android|          4G|         0|         17|   Thursday|         0|\n",
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.filter(F.col('transaction_status') == 'FAILED').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a25d925f-f415-425c-81c9-fcb9b0bcf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|receiver_age_group|\n",
      "+------------------+\n",
      "|             18-25|\n",
      "|             26-35|\n",
      "|               56+|\n",
      "|             46-55|\n",
      "|             36-45|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.select(F.col('receiver_age_group')).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2aecb2b2-84c6-487d-ae6b-7ec8f6a6bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "35e01c70-8eee-4cb0-949c-2ea40ba8c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df_renamed.withColumn(\"salt\", monotonically_increasing_id() % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "548d8402-7b90-4a45-94e1-f30be322f2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+--------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+----+\n",
      "|transaction_id|          timestamp|transaction_type|merchant_category|amount_inr|transaction_status|sender_age_group|receiver_age_group|  sender_state|sender_bank|receiver_bank|device_type|network_type|fraud_flag|hour_of_day|day_of_week|is_weekend|salt|\n",
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+--------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+----+\n",
      "| TXN0000000001|2024-11-05 15:30:02|             P2P|    Entertainment|       534|           SUCCESS|           26-35|             26-35|     Rajasthan|   IndusInd|          SBI|    Android|          4G|         0|         15|    Tuesday|         0|   0|\n",
      "| TXN0000000002|2024-04-10 12:13:08|             P2M|          Grocery|      1951|           SUCCESS|           26-35|             26-35|Andhra Pradesh|        SBI|         Axis|    Android|          4G|         0|         12|  Wednesday|         0|   1|\n",
      "| TXN0000000003|2024-04-12 17:59:54|             P2P|          Grocery|       388|           SUCCESS|           26-35|             26-35|         Delhi|      ICICI|        Kotak|        iOS|          4G|         0|         17|     Friday|         0|   2|\n",
      "| TXN0000000004|2024-10-22 22:59:54|             P2P|             Fuel|      1495|           SUCCESS|           26-35|             26-35|     Rajasthan|        SBI|         Axis|    Android|          4G|         0|         22|    Tuesday|         0|   3|\n",
      "| TXN0000000005|2024-08-12 12:21:34|             P2P|         Shopping|      4333|           SUCCESS|           18-25|             26-35|    Tamil Nadu|       HDFC|         HDFC|        iOS|          4G|         0|         12|     Monday|         0|   4|\n",
      "| TXN0000000006|2024-11-14 10:17:32|             P2P|             Food|       113|           SUCCESS|           18-25|             26-35|   West Bengal|   IndusInd|         HDFC|    Android|          4G|         0|         10|   Thursday|         0|   5|\n",
      "| TXN0000000007|2024-02-23 19:27:04|             P2P|            Other|       132|           SUCCESS|           18-25|             18-25|     Karnataka|   Yes Bank|     IndusInd|    Android|          4G|         0|         19|     Friday|         0|   6|\n",
      "| TXN0000000008|2024-01-14 19:17:30|             P2P|        Utilities|       774|           SUCCESS|           36-45|             18-25|     Karnataka|       HDFC|          SBI|        iOS|          5G|         0|         19|     Sunday|         1|   7|\n",
      "| TXN0000000009|2024-08-16 11:04:59|             P2P|            Other|       209|           SUCCESS|           26-35|             46-55|         Delhi|        PNB|         HDFC|    Android|          4G|         0|         11|     Friday|         0|   8|\n",
      "| TXN0000000010|2024-12-09 08:51:32|             P2M|          Grocery|       648|           SUCCESS|           26-35|             36-45|     Karnataka|      Kotak|        Kotak|    Android|          4G|         0|          8|     Monday|         0|   9|\n",
      "| TXN0000000011|2024-06-17 20:58:36|             P2P|             Food|       394|           SUCCESS|             56+|             26-35|     Rajasthan|      Kotak|     IndusInd|    Android|        WiFi|         0|         20|     Monday|         0|   0|\n",
      "| TXN0000000012|2024-05-16 00:04:26|             P2M|            Other|      1986|           SUCCESS|           36-45|             26-35|   Maharashtra|        SBI|          PNB|    Android|          4G|         0|          0|   Thursday|         0|   1|\n",
      "| TXN0000000013|2024-04-02 18:05:15|             P2P|        Transport|       620|           SUCCESS|           26-35|             26-35|   Maharashtra|        PNB|        ICICI|    Android|          4G|         0|         18|    Tuesday|         0|   2|\n",
      "| TXN0000000014|2024-12-07 14:19:02|    Bill Payment|          Grocery|       465|           SUCCESS|           36-45|             18-25|         Delhi|        PNB|        ICICI|    Android|          4G|         0|         14|   Saturday|         1|   3|\n",
      "| TXN0000000015|2024-08-11 09:42:04|             P2P|        Transport|       102|           SUCCESS|           26-35|             18-25|   Maharashtra|      ICICI|     IndusInd|    Android|          4G|         0|          9|     Sunday|         1|   4|\n",
      "| TXN0000000016|2024-06-13 22:31:06|             P2M|          Grocery|       293|           SUCCESS|           18-25|             26-35| Uttar Pradesh|       Axis|        Kotak|    Android|          3G|         0|         22|   Thursday|         0|   5|\n",
      "| TXN0000000017|2024-06-07 06:47:02|             P2P|             Food|       170|           SUCCESS|           26-35|             26-35|   West Bengal|   IndusInd|         HDFC|    Android|          4G|         0|          6|     Friday|         0|   6|\n",
      "| TXN0000000018|2024-10-04 16:33:40|             P2M|       Healthcare|       418|           SUCCESS|           46-55|             46-55|     Karnataka|        PNB|         HDFC|        iOS|          3G|         0|         16|     Friday|         0|   7|\n",
      "| TXN0000000019|2024-02-27 00:56:34|             P2P|       Healthcare|       214|           SUCCESS|           18-25|             18-25|     Telangana|        SBI|         HDFC|    Android|          5G|         0|          0|    Tuesday|         0|   8|\n",
      "| TXN0000000020|2024-12-24 23:11:52|             P2P|        Utilities|       749|           SUCCESS|           26-35|             26-35|   Maharashtra|        SBI|          SBI|    Android|          4G|         0|         23|    Tuesday|         0|   9|\n",
      "+--------------+-------------------+----------------+-----------------+----------+------------------+----------------+------------------+--------------+-----------+-------------+-----------+------------+----------+-----------+-----------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e200ce75-9ff2-46c5-a509-41491739ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data with duplicates\n",
    "\n",
    "gpt_df = spark.read.option('header',True).csv('data/sample_100k_with_duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "dae7333f-d244-43e0-93d2-6bb20ce8208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_dd = gpt_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "05462c2d-e022-49f9-bcda-1c6cc648ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_spec = Window.partitionBy(F.col('id')).orderBy(F.col('date').desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ea6e8f0c-b28f-44f3-8ee7-7548bc9eb8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----------+\n",
      "|   id|            name|      date|\n",
      "+-----+----------------+----------+\n",
      "|    1|  William Miller|2024-08-12|\n",
      "|  100|     Terry Clark|2024-08-25|\n",
      "| 1000| Timothy Johnson|2024-04-12|\n",
      "|10000| William Ramirez|2023-09-13|\n",
      "|10001|   Brenda Miller|2023-11-15|\n",
      "|10002|  Brandon Medina|2024-04-12|\n",
      "|10003| Valerie Johnson|2024-03-11|\n",
      "|10004|  Derrick Duncan|2024-06-02|\n",
      "|10005|     Henry Scott|2023-12-13|\n",
      "|10006|   Steven Lawson|2024-08-03|\n",
      "|10007| Jasmine Hawkins|2024-11-27|\n",
      "|10008|Tracey Maldonado|2024-04-05|\n",
      "|10009|   Jennifer Ball|2024-12-22|\n",
      "|10010|Stephen Ferguson|2024-07-05|\n",
      "|10014|Danielle Patrick|2024-01-31|\n",
      "|10015|     Jason Evans|2024-12-20|\n",
      "|10016|     Jean Fisher|2024-11-22|\n",
      "|10017| Nicole Martinez|2024-03-08|\n",
      "|10018|  Dr. Ryan Russo|2024-05-05|\n",
      "|10019| Kristine Barton|2024-10-06|\n",
      "+-----+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_dd_wf = (\n",
    "    gpt_df.withColumn('rn',F.row_number().over(wind_spec))\n",
    "    .filter(F.col('rn') == 1)\n",
    "    .orderBy(F.col('id'))\n",
    "    .drop(F.col('rn'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d38b32-9b9c-4c6b-b788-ea8dda15bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win = df_renamed.select(F.col('transaction_id'), F.col('amount_inr')).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50b61734-42b6-4320-8882-8592edfb3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|transaction_id|amount_inr|\n",
      "+--------------+----------+\n",
      "| TXN0000000001|       534|\n",
      "| TXN0000000002|      1951|\n",
      "| TXN0000000003|       388|\n",
      "| TXN0000000004|      1495|\n",
      "| TXN0000000005|      4333|\n",
      "| TXN0000000006|       113|\n",
      "| TXN0000000007|       132|\n",
      "| TXN0000000008|       774|\n",
      "| TXN0000000009|       209|\n",
      "| TXN0000000010|       648|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d527ddd-f200-48a4-92fd-64df21fed6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a217d1c7-4fd9-43fd-b1ea-97662ff72225",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(F.col('transaction_id')).rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
    "window_spec2 = Window.orderBy(F.col('transaction_id')).rowsBetween(start=-2,end=Window.currentRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dd21aa3-c239-4231-8141-6ff9298e2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/16 22:50:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+\n",
      "|transaction_id|amount_inr|rolling_sum|\n",
      "+--------------+----------+-----------+\n",
      "| TXN0000000001|       534|      534.0|\n",
      "| TXN0000000002|      1951|     2485.0|\n",
      "| TXN0000000003|       388|     2873.0|\n",
      "| TXN0000000004|      1495|     4368.0|\n",
      "| TXN0000000005|      4333|     8701.0|\n",
      "| TXN0000000006|       113|     8814.0|\n",
      "| TXN0000000007|       132|     8946.0|\n",
      "| TXN0000000008|       774|     9720.0|\n",
      "| TXN0000000009|       209|     9929.0|\n",
      "| TXN0000000010|       648|    10577.0|\n",
      "+--------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_win.withColumn('rolling_sum',F.sum(F.col('amount_inr')).over(window_spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "475660c3-c1eb-4209-a044-6b1e6c83670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+\n",
      "|transaction_id|amount_inr|rolling_sum|\n",
      "+--------------+----------+-----------+\n",
      "| TXN0000000001|       534|      534.0|\n",
      "| TXN0000000002|      1951|     2485.0|\n",
      "| TXN0000000003|       388|     2873.0|\n",
      "| TXN0000000004|      1495|     3834.0|\n",
      "| TXN0000000005|      4333|     6216.0|\n",
      "| TXN0000000006|       113|     5941.0|\n",
      "| TXN0000000007|       132|     4578.0|\n",
      "| TXN0000000008|       774|     1019.0|\n",
      "| TXN0000000009|       209|     1115.0|\n",
      "| TXN0000000010|       648|     1631.0|\n",
      "+--------------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/16 22:53:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "df_win.withColumn('rolling_sum',F.sum(F.col('amount_inr')).over(window_spec2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229335e4-75d8-4c31-aedd-ca8441ad47e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e5ea5-d808-4a82-bac1-e8a83581dab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab803b84-e7c8-40b0-9e6d-deed87ebb44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "629a2a4c-3449-421f-8f8a-13b851dfec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7299bd63-f4f8-4ba8-adad-63c11bed1631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hari']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hari\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "097a39dc-f89e-49cf-879c-84a54b5f2707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hari prasath'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['hari','prasath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a2ef4ce-1bde-48c8-a69b-e20565b335c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4bc1e4a3-5a49-42ad-9270-5759ab1e1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = \"hari     Prasath is   a data   engineer             \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74bfa56c-57e8-435f-849c-8353f4befb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hari prasath is a data engineer'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\s+\",\" \",rg).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8af9eb54-b5e2-48f8-a4ff-9f309caf8974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hari     Prasath Is   A Data   Engineer             '"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b20674ce-2b47-406e-b8e4-68093c8c3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARI     pRASATH IS   A DATA   ENGINEER             '"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13abbde7-2a43-430b-894c-5f0ee6ae641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hari\n",
      "      hari\n",
      "           hari\n",
      "                hari\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print('hari'.rjust(i*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f2a53-5185-47d9-8888-0f95e654eeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
